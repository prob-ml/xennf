{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/diff-i93oUBlF-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# PyTorch and Pyro imports\n",
    "import torch\n",
    "import zuko\n",
    "import numpy as np\n",
    "from torch import Size, Tensor\n",
    "import pyro\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO\n",
    "from pyro.optim import Adam, PyroOptim, ClippedAdam\n",
    "from pyro.infer.mcmc.mcmc_kernel import MCMCKernel\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.transforms as T\n",
    "from pyro.distributions.transforms import Spline, ComposeTransform\n",
    "from pyro.distributions import TransformedDistribution\n",
    "\n",
    "# Utility imports\n",
    "import GPUtil\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import ARI, NMI\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Custom module imports\n",
    "from xenium_cluster import XeniumCluster\n",
    "from data import prepare_DLPFC_data, prepare_synthetic_data, prepare_Xenium_data\n",
    "from zuko_flow import setup_zuko_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAY! GPU available :3\n",
      "Using GPU: 1 with the lowest memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/diff-i93oUBlF-py3.10/lib/python3.10/site-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "# cuda setup\n",
    "if torch.cuda.is_available():\n",
    "    print(\"YAY! GPU available :3\")\n",
    "    \n",
    "    # Get all available GPUs sorted by memory usage (lowest first)\n",
    "    available_gpus = GPUtil.getAvailable(order='memory', limit=1)\n",
    "    \n",
    "    if available_gpus:\n",
    "        selected_gpu = available_gpus[0]\n",
    "        \n",
    "        # Set the GPU with the lowest memory usage\n",
    "        torch.cuda.set_device(selected_gpu)\n",
    "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        print(f\"Using GPU: {selected_gpu} with the lowest memory usage.\")\n",
    "    else:\n",
    "        print(\"No GPUs available with low memory usage.\")\n",
    "else:\n",
    "    print(\"No GPU available :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZukoToPyro(pyro.distributions.TorchDistribution):\n",
    "    r\"\"\"Wraps a Zuko distribution as a Pyro distribution.\n",
    "\n",
    "    If ``dist`` has an ``rsample_and_log_prob`` method, like Zuko's flows, it will be\n",
    "    used when sampling instead of ``rsample``. The returned log density will be cached\n",
    "    for later scoring.\n",
    "\n",
    "    :param dist: A distribution instance.\n",
    "    :type dist: torch.distributions.Distribution\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        flow = zuko.flows.MAF(features=5)\n",
    "\n",
    "        # flow() is a torch.distributions.Distribution\n",
    "\n",
    "        dist = flow()\n",
    "        x = dist.sample((2, 3))\n",
    "        log_p = dist.log_prob(x)\n",
    "\n",
    "        # ZukoToPyro(flow()) is a pyro.distributions.Distribution\n",
    "\n",
    "        dist = ZukoToPyro(flow())\n",
    "        x = dist((2, 3))\n",
    "        log_p = dist.log_prob(x)\n",
    "\n",
    "        with pyro.plate(\"data\", 42):\n",
    "            z = pyro.sample(\"z\", dist)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dist: torch.distributions.Distribution):\n",
    "        self.dist = dist\n",
    "        self.cache = {}\n",
    "\n",
    "    @property\n",
    "    def has_rsample(self) -> bool:\n",
    "        return self.dist.has_rsample\n",
    "\n",
    "    @property\n",
    "    def event_shape(self) -> Size:\n",
    "        return self.dist.event_shape\n",
    "\n",
    "    @property\n",
    "    def batch_shape(self) -> Size:\n",
    "        return self.dist.batch_shape\n",
    "\n",
    "    def __call__(self, shape: Size = ()) -> Tensor:\n",
    "        if hasattr(self.dist, \"rsample_and_log_prob\"):  # fast sampling + scoring\n",
    "            x, self.cache[x] = self.dist.rsample_and_log_prob(shape)\n",
    "        elif self.has_rsample:\n",
    "            x = self.dist.rsample(shape)\n",
    "        else:\n",
    "            x = self.dist.sample(shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def log_prob(self, x: Tensor) -> Tensor:\n",
    "        if x in self.cache:\n",
    "            return self.cache[x]\n",
    "        else:\n",
    "            return self.dist.log_prob(x)\n",
    "\n",
    "    def expand(self, *args, **kwargs):\n",
    "        return ZukoToPyro(self.dist.expand(*args, **kwargs))\n",
    "    \n",
    "    def rsample(self, sample_shape=torch.Size()):\n",
    "        return self.dist.rsample(sample_shape)  # Delegate to the underlying flow\n",
    "\n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        return self.dist.sample(sample_shape)  # Delegate to the underlying flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potts Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Potts prior is a prior distribution of cluster assignments given neighboring states. The general form of the Potts model is $$\\pi(z_i) \\propto \\exp \\left( \\sum_i H(z_i) + \\sum_{(i,j) \\in G} J(z_i, z_j)\\right)$$. H is the local potention representing some external influence of bias on the spot i. J is the interaction energy between neighboring sites. This represents the neighboring signals of spots, which is how we enforce the spatial clustering. The BayesSpace formulation feels like a more natural representation of this concept. $$\\pi(z_i) \\propto \\exp \\left( \\frac{\\gamma}{\\langle ij \\rangle} * 2\\sum_{\\langle ij \\rangle} I(z_i = z_j)\\right)$$ $\\gamma$ is a smoothing parameter which can be tuned to increase the spatial contiguity of spatial assignments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Potts2D(dist.Distribution):\n",
    "\n",
    "    def __init__(self, current_state, batch_idx, num_clusters=7, radius=1, gamma=1.5):\n",
    "        super().__init__()\n",
    "        self.current_state = current_state\n",
    "        self.batch_idx = batch_idx\n",
    "        self.num_clusters = num_clusters\n",
    "        self.radius = radius\n",
    "        self.gamma = gamma\n",
    "        self.num_rows, self.num_cols = current_state.shape\n",
    "\n",
    "    @property\n",
    "    def batch_shape(self):\n",
    "        # The shape of the grid\n",
    "        return torch.Size([len(self.batch_idx)])\n",
    "\n",
    "    @property\n",
    "    def event_shape(self):\n",
    "        # No event dimensions (this is over the whole grid)\n",
    "        return torch.Size([])\n",
    "\n",
    "    def expand(self, batch_shape, _instance=None):\n",
    "        # Create a new instance of Potts2D with the same parameters but a new batch shape\n",
    "        new_instance = Potts2D(\n",
    "            current_state=self.current_state,\n",
    "            batch_idx=self.batch_idx,\n",
    "            num_clusters=self.num_clusters,\n",
    "            radius=self.radius,\n",
    "            gamma=self.gamma,\n",
    "        )\n",
    "        return new_instance\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.sample()\n",
    "\n",
    "    def get_neighbors(self, i, j):\n",
    "        neighbors = []\n",
    "        for x in range(max(0, i - self.radius), min(self.current_state.shape[0], i + self.radius + 1)):\n",
    "            for y in range(max(0, j - self.radius), min(self.current_state.shape[1], j + self.radius + 1)):\n",
    "                if abs(x - i) + abs(y - j) <= self.radius:\n",
    "                    neighbors.append((x, y))\n",
    "        return neighbors\n",
    "\n",
    "    def sample(self):\n",
    "        num_rows, num_cols = self.current_state.shape\n",
    "\n",
    "        new_state = self.current_state.clone() \n",
    "        new_soft_state = torch.zeros(new_state.size(0), new_state.size(1), self.num_clusters)\n",
    "        \n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_cols):\n",
    "            # Compute conditional probabilities for site i\n",
    "                probs = torch.zeros(self.num_clusters)\n",
    "                for k in range(1, self.num_clusters + 1):\n",
    "                    # Compute the contribution of neighbors\n",
    "                    probs[k-1] = torch.sum(\n",
    "                        torch.tensor(\n",
    "                            [2 * self.gamma if new_state[a][b] == k else 0.0 for (a, b) in self.get_neighbors(i, j)]\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                # Normalize to get valid probabilities\n",
    "                probs = torch.exp(probs - torch.max(probs))  # Avoid numerical issues\n",
    "                probs /= probs.sum()\n",
    "                probs = torch.clamp(probs, min=0.0001)\n",
    "                new_soft_state[i][j] = probs\n",
    "                new_state[i][j] = torch.multinomial(probs, 1).item()\n",
    "\n",
    "        self.current_state = new_state\n",
    "        \n",
    "        MIN_PROB = 0.01\n",
    "        return torch.clamp(new_soft_state.reshape(-1, self.num_clusters)[self.batch_idx], min=MIN_PROB)\n",
    "\n",
    "    def log_prob(self, cluster_probs):\n",
    "\n",
    "        if cluster_probs.dim() == 2:\n",
    "\n",
    "            cluster_state_flattened = self.current_state.reshape(-1,1)[self.batch_idx]\n",
    "\n",
    "            # -1 is for indexing purposes. The 0 cluster is for empty cells.\n",
    "            # print(cluster_probs.shape)\n",
    "            # print(range(cluster_state_flattened.size(0)))\n",
    "            # print(cluster_state_flattened.flatten() - 1)\n",
    "            cluster_prob_tensor = cluster_probs[range(cluster_state_flattened.size(0)), cluster_state_flattened.flatten() - 1]\n",
    "\n",
    "            log_prob_tensor = torch.log(cluster_prob_tensor)\n",
    "\n",
    "        else:\n",
    "\n",
    "            cluster_state_flattened = self.current_state.reshape(-1,1)[self.batch_idx]\n",
    "\n",
    "            # -1 is for indexing purposes. The 0 cluster is for empty cells.\n",
    "            cluster_prob_tensor = cluster_probs[:, range(cluster_state_flattened.size(0)), cluster_state_flattened.flatten() - 1]\n",
    "\n",
    "            log_prob_tensor = torch.log(cluster_prob_tensor)\n",
    "\n",
    "        return log_prob_tensor  # Return the sum of all values in log_prob_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the simulated dataset from the BayXenSmooth paper as an initial assessment of our idea. To make this happen we need to load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Properties\n",
    "batch_size = 256\n",
    "data_dimension = 5\n",
    "num_clusters = 7\n",
    "learn_global_variances = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHwCAYAAAC7cCafAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+80lEQVR4nO3deXxU1f3/8fedQCZAFghLQiSBiMhaQEExgKiIpGBRBEUQf+z2WxtUiFjFDWjR0LqA1gDWUtAqYkXRFgVqkaWyCASxoIKgsUYhgBYSEkzAmfv7g2bqOFkndzJzJ6/n43EfD+fcmXPP3AQ/+ZzlHsM0TVMAACBsOILdAAAAYC2COwAAYYbgDgBAmCG4AwAQZgjuAACEGYI7AABhhuAOAECYIbgDABBmCO4AAIQZgjsAAGGG4A4AQC19/fXXuvXWW9W8eXM1atRIP/nJT7Rr166gtadB0K4MAEAYOHHihPr166errrpKa9asUcuWLXXw4EE1a9YsaG0y2DgGAAD/3XfffdqyZYv++c9/BrspHnTLAwBQC3/961/Vu3dv3XTTTWrVqpUuuugiPffcc0FtE5k7AMC2SkpKdObMmYDUbZqmDMPwKnM6nXI6nV5lUVFRkqTMzEzddNNN2rlzp+666y4tXrxY48ePD0jbqkJwBwDYUklJiVIbNVJ+gOqPjo5WUVGRV9msWbM0e/Zsr7LIyEj17t1bW7du9ZTdeeed2rlzp7Zt2xag1lWOCXUAAFs6c+aM8iXlOQzFWlx3oaTkoiLl5eUpNvZ/tf84a5ek1q1bq0uXLl5lnTt31muvvWZxq6qP4A4AsLVYSbE/6j6vtf92asfGxnoF9/L069dPBw4c8Cr79NNP1bZtW2vbVAMEdwCAvUUYkuXBXZK7eqPW06dPV9++ffXoo49q1KhR2rFjh/7whz/oD3/4g7VtqgHG3AEAtlRYWKi4uDgVNHRYnrkXmqbizrpVUFBQZeYuSatXr9bMmTN18OBBpaamKjMzU7fddpulbaoJgjsAwJY8wT2qQWCCe8n31Q7uoYZ17gAAhBnG3AEA9tYgQGPuNkbmDgBAmCFzBwDYW4QjAJm7vVN3gjsAwN4cxrnDSm5rq6trdMsDABBmyNwBAPYW4bA+czfs3S1P5g4AQJghcwcA2BuZuw8ydwAAwgyZOwDA3iICMFve4urqGpk7AABhhswdAGBvjLn7ILgDAOyNbnkfdMsDABBmyNwBAPYWYZzrmreSy97PnyVzR71lGIZmz54d7GZUasKECYqOjq6Ta23cuFGGYWjjxo11cj0AgUNwR6Vyc3M1depUXXjhhWrcuLEaN26sLl26KCMjQ//617+C3byAuvLKK2UYRpVHbf9AOH36tGbPnh3QoLpq1SoNGTJELVq0UGRkpJKSkjRq1Ci9++67Abvmj23dulWzZ8/WyZMn6+yaqCcijMAcNka3PCq0evVq3XzzzWrQoIHGjh2rHj16yOFwaP/+/Xr99de1aNEi5ebmqm3btsFuakA88MADmjJliuf1zp079fTTT+v+++9X586dPeXdu3ev1XVOnz6tOXPmSDr3B4WVTNPUpEmTtGzZMl100UXKzMxUYmKijhw5olWrVunqq6/Wli1b1LdvX0uvW56tW7dqzpw5mjBhgpo2bRrw6wH1GcEd5frss880evRotW3bVuvXr1fr1q29zv/2t7/VwoUL5XBU3vlTXFysJk2aBLKpAXPNNdd4vY6KitLTTz+ta665ptIgHErf+YknntCyZcs0bdo0PfnkkzJ+sOf1Aw88oD//+c9q0MDe/xs4ffq0GjduHOxmIJgiHNaPudscdwPl+t3vfqfi4mItXbrUJ7BLUoMGDXTnnXcqOTnZU1Y2PvzZZ59p6NChiomJ0dixYyWdC3h33323kpOT5XQ61bFjRz3++OMyzf+tJf3iiy9kGIaWLVvmc70fd3/Pnj1bhmHo0KFDnkwwLi5OEydO1OnTp70+W1paqunTp6tly5aKiYnRddddp6+++qqWd8i7HR9//LFuueUWNWvWTP3795d0Lgsv74+ACRMmqF27dp7v3LJlS0nSnDlzKuzq//rrrzV8+HBFR0erZcuWmjFjhlwuV6Vt++6775SVlaVOnTrp8ccf9wrsZf7f//t/uvTSSyuso127dpowYYJPeXnf7fe//726du2qxo0bq1mzZurdu7eWL18u6dx9uueeeyRJqampnu/5xRdfeD7/4osvqlevXmrUqJHi4+M1evRo5eXl+Vy3W7duysnJ0YABA9S4cWPdf//9kqRdu3YpPT1dLVq0UKNGjZSamqpJkyZVeo+AcGXvP9kRMKtXr9YFF1ygPn361Ohz33//vdLT09W/f389/vjjaty4sUzT1HXXXacNGzZo8uTJ6tmzp9atW6d77rlHX3/9tebPn+93O0eNGqXU1FRlZWVp9+7d+uMf/6hWrVrpt7/9rec9U6ZM0YsvvqhbbrlFffv21bvvvqtrr73W72uW56abblKHDh306KOPev3BUpWWLVtq0aJFuv3223XDDTdoxIgRkry7+l0ul9LT09WnTx89/vjj+sc//qEnnnhC7du31+23315h3e+9957+85//aNq0aYqIiPD/y1XDc889pzvvvFM33nij7rrrLpWUlOhf//qX3n//fd1yyy0aMWKEPv30U7388suaP3++WrRo4fn+kvTII4/ooYce0qhRozRlyhQdP35cv//97zVgwAB98MEHXt343377rYYMGaLRo0fr1ltvVUJCgo4dO6bBgwerZcuWuu+++9S0aVN98cUXev311wP6vREiyNx9ENzho7CwUIcPH9bw4cN9zp08eVLff/+953WTJk3UqFEjz+vS0lLddNNNysrK8pS9+eabevfddzV37lw98MADkqSMjAzddNNNeuqppzR16lS1b9/er7ZedNFFWrJkief1t99+qyVLlniC+4cffqgXX3xRv/zlL5Wdne259tixYy2dENijRw9PlloTTZo00Y033qjbb79d3bt316233urznpKSEt1888166KGHJEm/+MUvdPHFF2vJkiWVBvdPPvlEkvSTn/ykxu2qqbfeektdu3bVq6++Wu757t276+KLL9bLL7+s4cOHe3ouJOnf//63Zs2apblz53qycEkaMWKELrroIi1cuNCrPD8/X4sXL9b//d//ecreeOMNnThxQn//+9/Vu3dvT/ncuXMt/JYIWQGZAGfvCXX8qQMfhYWFklTuEqwrr7xSLVu29BxlAfOHfhxw3n77bUVEROjOO+/0Kr/77rtlmqbWrFnjd1t/8YtfeL2+/PLL9e2333q+w9tvvy1JPteeNm2a39esTjusVt73/Pzzzyv9TNk9iImJCVi7yjRt2lRfffWVdu7cWePPvv7663K73Ro1apS++eYbz5GYmKgOHTpow4YNXu93Op2aOHGiz/Wlcz1OZ8+e9ft7AOGC4A4fZcGgqKjI59yzzz6rd955Ry+++GK5n23QoIHatGnjVfbvf/9bSUlJPkGmbMb5v//9b7/bmpKS4vW6WbNmkqQTJ0546nY4HD49Ax07dvT7muVJTU21tL4fioqK8nRfl2nWrJnnO1YkNjZWknTq1KmAta3Mvffeq+joaF166aXq0KGDMjIytGXLlmp99uDBgzJNUx06dPD6w7Fly5b65JNPdOzYMa/3n3feeYqMjPQqu+KKKzRy5EjNmTNHLVq00PXXX6+lS5eqtLTUsu+IEFbWLW/1YWN0y8NHXFycWrdurX379vmcKxuD/+FEqB9yOp1VzqCvSHkTviRVOnGsorHkmox7W+GHQxNlDMMotx1VTYT7MX/Hyzt16iRJ2rt3b7lDLNVR2c/kh+3q3LmzDhw4oNWrV2vt2rV67bXXtHDhQj388MOeZX4VcbvdMgxDa9asKfe7/rgHqaJ7vXLlSm3fvl1/+9vftG7dOk2aNElPPPGEtm/fXmcPAgJChb3/NEHAXHvttTp06JB27NhR67ratm2rw4cP+2SQ+/fv95yX/pd1//ghJ7XJ7Nu2bSu3263PPvvMq/zAgQN+11ldzZo1K/eBLT/+PhUF0Nrq37+/mjVrppdffrnGf1CUqe53kM7NH7j55pu1dOlSffnll7r22mv1yCOPqKSkRFLF37N9+/YyTVOpqakaNGiQz3HZZZdVu72XXXaZHnnkEe3atUsvvfSSPvroI61YsaLan4dNOQLwABurN6KpYwR3lOtXv/qVGjdurEmTJuno0aM+52uSGQ8dOlQul0vPPPOMV/n8+fNlGIaGDBki6Vw3cosWLbR582av9y1cuNCPb3BOWd1PP/20V/mCBQv8rrO62rdvr/379+v48eOesg8//NCnu7psjbbVT25r3Lix7r33Xn3yySe69957y/2Zvfjii5X+Ade+fXtt375dZ86c8ZStXr3aZ4nat99+6/U6MjJSXbp0kWmanjHwsrX/P/6eI0aMUEREhObMmePTRtM0feouz4kTJ3w+27NnT0miax71Et3yKFeHDh20fPlyjRkzRh07dvQ8oc40TeXm5mr58uVyOBw+4+vlGTZsmK666io98MAD+uKLL9SjRw/9/e9/15tvvqlp06Z5jYdPmTJF8+bN05QpU9S7d29t3rxZn376qd/fo2fPnhozZowWLlyogoIC9e3bV+vXr9ehQ4f8rrO6Jk2apCeffFLp6emaPHmyjh07psWLF6tr166eyW7SuW7mLl266JVXXtGFF16o+Ph4devWTd26dat1G+655x599NFHeuKJJ7RhwwbdeOONSkxMVH5+vt544w3t2LFDW7durfDzU6ZM0cqVK/XTn/5Uo0aN0meffaYXX3zRZw7D4MGDlZiYqH79+ikhIUGffPKJnnnmGV177bWeuRa9evWSdO7hOaNHj1bDhg01bNgwtW/fXnPnztXMmTP1xRdfaPjw4YqJiVFubq5WrVqln//855oxY0al3/P555/XwoULdcMNN6h9+/Y6deqUnnvuOcXGxmro0KG1vIsIeYEYI7f3du6SCVTi0KFD5u23325ecMEFZlRUlNmoUSOzU6dO5i9+8Qtzz549Xu8dP3682aRJk3LrOXXqlDl9+nQzKSnJbNiwodmhQwfzscceM91ut9f7Tp8+bU6ePNmMi4szY2JizFGjRpnHjh0zJZmzZs3yvG/WrFmmJPP48eNen1+6dKkpyczNzfWUfffdd+add95pNm/e3GzSpIk5bNgwMy8vz6fOqrz66qumJHPDhg1VtqPMiy++aJ5//vlmZGSk2bNnT3PdunXm+PHjzbZt23q9b+vWrWavXr3MyMhIr3ZVdE/LrltdK1euNAcPHmzGx8ebDRo0MFu3bm3efPPN5saNGz3v2bBhg8/3M03TfOKJJ8zzzjvPdDqdZr9+/cxdu3aZV1xxhXnFFVd43vPss8+aAwYMMJs3b246nU6zffv25j333GMWFBR41fWb3/zGPO+880yHw+Hzc3rttdfM/v37m02aNDGbNGlidurUyczIyDAPHDjgec8VV1xhdu3a1ef77d692xwzZoyZkpJiOp1Os1WrVubPfvYzc9euXdW+R7CfgoICU5JZ0KeNafZLsfQo6NPmXN0/+h22C8M063jmEQAAFigsLFRcXJwK+iYrtoG1mXvh927Fbc1TQUGBZ+WJndAtDwCwN7rlfTChDgCAMEPmDgCwt0A8ftZkKRwAAAghZO4AAHtjzN0HmTsAAGEm5DJ3t9utw4cPKyYmJmCP5QQABJ5pmjp16pSSkpL83nOiWhyG9Zm7296pe8gF98OHDys5OTnYzQAAWCQvL69aT7OEdUIuuJc9qnK68uSU/R4cAPzQG/d+F+wmAEHjKj2lgws6+Gz3bLlAzJZ327vnOOSCe1lXvFOxBHfYXoSzYbCbAARdwIdYAzGhzubd8kyoAwAgzIRc5g4AQI3QLe+DzB0AgDBD5g4AsDfG3H2QuQMAEGbI3AEA9saYuw8ydwAAwgyZOwDA3hwBGHN32XvMneAOALC3QHTLW11fHaNbHgCAMEPmDgCwt0AshYuwd7c8mTsAAGGGzB0AYG+MufsgcwcAIMyQuQMA7I0xdx9k7gAAhBkydwCAvUUYAcjc3dbWV8cI7gAAe3MY5w6r67QxuuUBAAgzZO5ALa18+LtgNwGo3wLxbHmHvXNfe7ceAAD4IHMHANgbD7HxQeYOAECYIXMHANhbQB5iY+/c196tBwAAPgjuAAB7Kxtzt/qoptmzZ8swDK+jU6dOAfzCVaNbHgBgbw6H9UvXalhf165d9Y9//MPzukGD4IZXgjtQBdaxA6hKgwYNlJiYGOxmeNAtDwCwtyB3y0vSwYMHlZSUpPPPP19jx47Vl19+GaAvWz1k7gAAVKCwsNDrtdPplNPp9Crr06ePli1bpo4dO+rIkSOaM2eOLr/8cu3bt08xMTF12VwPgjsAwN4C+PjZ5ORkr+JZs2Zp9uzZXmVDhgzx/Hf37t3Vp08ftW3bVn/5y180efJka9tVTQR3AAAqkJeXp9jYWM/rH2ft5WnatKkuvPBCHTp0KJBNqxRj7gAAewvgmHtsbKzXUZ3gXlRUpM8++0ytW7cO9DevEMEdAIBamDFjhjZt2qQvvvhCW7du1Q033KCIiAiNGTMmaG2iWx5hgyVrQD0V5HXuX331lcaMGaNvv/1WLVu2VP/+/bV9+3a1bNnS2jbVAMEdAIBaWLFiRbCb4IPgDgCwN7Z89UFwBwDYW4QRgF3h7B3cmVAHAECYIXMHANibwzh3WF2njZG5AwAQZsjcAQD2FhGAx89aXV8dI7jDcqw3B4DgIrgDAOzNCMCYu8GYOwAACCFk7gAAe2PM3QfBHQBgbyyF82HvP00AAIAPMncAgL3RLe+D4F6PsWStesxxh4PdBB/GC0nBbgKAEEZwBwDYG2PuPuzd7wAAAHyQuQMA7I0xdx/2bj0AAPBB5g4AsDfG3H0Q3AEA9uYIQLe8w94d2/ZuPQAA8EHmHgLq03rzUFwzbkeBvI+soYft0C3vg8wdAIAwQ+YOALA3h8P6MXLG3AEAQCghcwcA2FuEpAiLx8gjrK2urpG5AwAQZsjcAQD2xpi7j1oF93nz5mnmzJm66667tGDBAklSSUmJ7r77bq1YsUKlpaVKT0/XwoULlZCQUKO637j3O0U4G9ameaiFUFyyNur8T4LdhDr1l887B+W6lf3sWSaHkMRSOB9+/2myc+dOPfvss+revbtX+fTp0/W3v/1Nr776qjZt2qTDhw9rxIgRtW4oAACoHr+Ce1FRkcaOHavnnntOzZo185QXFBRoyZIlevLJJzVw4ED16tVLS5cu1datW7V9+3bLGg0AgEeEEZjDxvwK7hkZGbr22ms1aNAgr/KcnBydPXvWq7xTp05KSUnRtm3byq2rtLRUhYWFXgcAAPBfjcfcV6xYod27d2vnzp0+5/Lz8xUZGammTZt6lSckJCg/P7/c+rKysjRnzpyaNgMAgHOYUOejRq3Py8vTXXfdpZdeeklRUVGWNGDmzJkqKCjwHHl5eZbUCwBAfVWjzD0nJ0fHjh3TxRdf7ClzuVzavHmznnnmGa1bt05nzpzRyZMnvbL3o0ePKjExsdw6nU6nnE6nf60HANR7bsOQ2+LZ7W7D3mPuNQruV199tfbu3etVNnHiRHXq1En33nuvkpOT1bBhQ61fv14jR46UJB04cEBffvml0tLSrGs1AACoUI2Ce0xMjLp16+ZV1qRJEzVv3txTPnnyZGVmZio+Pl6xsbG64447lJaWpssuu8y6VsMjGOvR69t682AJ1H2uzfr5qn7fWAePYHA7HHJbPEZudX11zfIn1M2fP18Oh0MjR470eogNAACB4HYEoFve5g+xqXVw37hxo9frqKgoZWdnKzs7u7ZVAwAAP/BseQCArbkiHHJFWNuNbnV9dc3erQcAAD7I3AEAtsaYuy8ydwAAwkzIZu7m6CMyY4qC3QxbC9aStRs/3xWU69YnK8/v7fdnq/q9CNRSOZbJIVBMh0OmxUvXrK6vrtm79QAAwEfIZu4AAFQHY+6+CO4AAFsjuPuiWx4AgDBD5g4AsLVzmbvVz5YncwcAACGEzB0AYGtmAPZzN+vTfu4IDNaj/0/XFzYHuwl15qNxA/z+bG1+dlWtka/s95HtYgF7ILgDAGzNZTjkMizeOMbi+uqavVsPAAB8kLkDAGyNde6+CO4AAFsjuPuiWx4AgDBD5g4AsDV2hfMVssH9htRPFRXbONjNCHnBWM5Wn5arBVIg72Nly+yq+p2pbKkc28UC9hCywR0AgOpgzN2XvfsdAACADzJ3AICtuR2OAGwcY+/c196tBwAAPsjcAQC25jYMuS3e6MXq+uoawR0AYGtMqPNFcLcIO6zVgV9vCHYLau7hq4Jy2cp+9lXtRlfZ7zI7ygH2wJg7AMDWzP9OqLPyqM1DbObNmyfDMDRt2jTrvmQNEdwBALDIzp079eyzz6p79+5BbQfBHQBgay4ZchkWH6r5mHtRUZHGjh2r5557Ts2aNQvAN60+gjsAABbIyMjQtddeq0GDBgW7KUyoAwDY27nZ8lY/xOZc5l5YWOhV7nQ65XQ6fd6/YsUK7d69Wzt37rS0Hf4icwcAoALJycmKi4vzHFlZWT7vycvL01133aWXXnpJUVFRQWilLzJ3AICtmYYh0+KHzpTVl5eXp9jYWE95eVl7Tk6Ojh07posvvthT5nK5tHnzZj3zzDMqLS1VRESEpe2rSsgG9+G5Hyg6xvcm1jchuVbdjuvNgyVQ96oW6+er+p2y43axQKDExsZ6BffyXH311dq7d69X2cSJE9WpUyfde++9dR7YpRAO7gAAVEewn1AXExOjbt26eZU1adJEzZs39ymvKwR3AICtuQ2H3IbFE+osrq+uEdwBALDYxo0bg3p9gjsAwNaC3S0fiuzd7wAAAHyQuQMAbI393H0R3OtASC5nk1jSZmdV/ewCtFQukNvF1kZlW8KyHSzqI4I7AMDW3A6HXJY/ftbeo9b2bj0AAPBB5g4AsDXG3H0R3AEAtkZw90W3PAAAYYbMHQBga6bDIdPiCXBW11fX7N16AADgg8zdIiG5lp117PVXZT/7WqyBD6TKtoStzXawrIEPf4y5+yJzBwAgzJC5AwBsjczdF5k7AABhhswdAGBrbgUgc5e9M3eCOwDA1tyGQ27D4mfLW1xfXbN36wEAgA8y92oKyaVuEsvdUKeq+ndQ2ZawlW0HK1W+JWxly+Sk2i2Vg/25DesnwLnt3StP5g4AQLghcwcA2JrbYcjlsDhzt7i+ukbmDgBAmCFzBwDYGrPlfdm79QAAwAeZOwDA1kzDkGnxbHmr66trNcrcFy1apO7duys2NlaxsbFKS0vTmjVrPOdLSkqUkZGh5s2bKzo6WiNHjtTRo0ctbzQAAGXcMgJy2FmNMvc2bdpo3rx56tChg0zT1PPPP6/rr79eH3zwgbp27arp06frrbfe0quvvqq4uDhNnTpVI0aM0JYtWwLV/vDHOnZYrarfqVpsCVvZOvjK1sADsFaNgvuwYcO8Xj/yyCNatGiRtm/frjZt2mjJkiVavny5Bg4cKElaunSpOnfurO3bt+uyyy6zrtUAAPwXu8L58nvM3eVy6dVXX1VxcbHS0tKUk5Ojs2fPatCgQZ73dOrUSSkpKdq2bRvBHQCA/2rWrJmMav4B8Z///KfG9dc4uO/du1dpaWkqKSlRdHS0Vq1apS5dumjPnj2KjIxU06ZNvd6fkJCg/Pz8CusrLS1VaWmp53VhYWFNmwQAqMfsuBRuwYIFAa2/xsG9Y8eO2rNnjwoKCrRy5UqNHz9emzZt8rsBWVlZmjNnjt+fBwDAbsaPHx/Q+mv8p0lkZKQuuOAC9erVS1lZWerRo4eeeuopJSYm6syZMzp58qTX+48eParExMQK65s5c6YKCgo8R15eXo2/BACg/iobc7f6qEufffaZHnzwQY0ZM0bHjh2TJK1Zs0YfffSRX/XVut/B7XartLRUvXr1UsOGDbV+/XrPuQMHDujLL79UWlpahZ93Op2epXVlBwAA9cWmTZv0k5/8RO+//75ef/11FRUVSZI+/PBDzZo1y686a9QtP3PmTA0ZMkQpKSk6deqUli9fro0bN2rdunWKi4vT5MmTlZmZqfj4eMXGxuqOO+5QWlqabSbTBW1bV5a7IZRU9vtYi2VyValsS9jKtoOtDXPc4UrPGy8kBeS6sJbLMOSyONO2ur7K3HfffZo7d64yMzMVExPjKR84cKCeeeYZv+qsUXA/duyYxo0bpyNHjiguLk7du3fXunXrdM0110iS5s+fL4fDoZEjR6q0tFTp6elauHChXw0DAKA67L4Ubu/evVq+fLlPeatWrfTNN9/4VWeNgvuSJUsqPR8VFaXs7GxlZ2f71RgAAOqbpk2b6siRI0pNTfUq/+CDD3Teeef5VScbxwAAbM0tR0COujJ69Gjde++9ys/Pl2EYcrvd2rJli2bMmKFx48b5VSfBHQCAIHr00UfVqVMnJScnq6ioSF26dNGAAQPUt29fPfjgg37Vya5wAAB7C8CucKrDMffIyEg999xzeuihh7Rv3z4VFRXpoosuUocOHfyuk+AOAEAQvffee+rfv79SUlKUkpJiSZ10ywMAbM3uD7EZOHCgUlNTdf/99+vjjz+2pE6COwAAQXT48GHdfffd2rRpk7p166aePXvqscce01dffeV3nQR3AICtuWUE5KgrLVq00NSpU7VlyxZ99tlnuummm/T888+rXbt2ni3Ua4oxdwCArZ3rRrd6V7jg7Oeempqq++67Tz169NBDDz3k98ZsZO4AAISALVu26Je//KVat26tW265Rd26ddNbb73lV11k7gAAWwtEN3pddsvPnDlTK1as0OHDh3XNNdfoqaee0vXXX6/GjRv7XSfBHQCAINq8ebPuuecejRo1Si1atLCkToI7AMDW7L5xzJYtWyyvk+AOwPZGnf9Jhef+8nlnv+utbEtYtoOFlf785z9r8eLFys3N1bZt29S2bVstWLBAqampuv7662tcHxPqAAC25pIRkKOuLFq0SJmZmRo6dKhOnjwpl8sl6dxucQsWLPCrToI7AABB9Pvf/17PPfecHnjgAUVERHjKe/furb179/pVJ93yAABbs/uYe25uri666CKfcqfTqeLiYr/qJHMHANiaKSMgR11JTU3Vnj17fMrXrl2rzp39mzNC5g4AQBBlZmYqIyNDJSUlMk1TO3bs0Msvv6ysrCz98Y9/9KtOgjsAwNZMw2H542dNi+urzJQpU9SoUSM9+OCDOn36tG655RYlJSXpqaee0ujRo/2qk255AACCbOzYsTp48KCKioqUn5+vr776SmPGjNHWrVv9qo/MHQD8UNkaeIl18HXJ7o+f/aHGjRt7Hjt78OBBXX755Z6lcTVB5g4AQJghcwcA2Fo4Ze5WIXMHACDMkLkDAGzNrpn7X//610rP5+bm+l03wR0AYGsuw5DL4ifKWV1feYYPH17leww/20FwBwAgCNxud8DqJrgDqBNdX9hc6fmPxg2oo5bUjaqWytUH5qlT0m8Dfx27dssHEhPqAAAIM2TuAABbc8sht8W5qtX11TV7tx4AgCBbtGiRunfvrtjYWMXGxiotLU1r1qwJapsI7gAAWwv2lq9t2rTRvHnzlJOTo127dmngwIG6/vrr9dFHH1X5WZfLpc2bN+vkyZO1uAO+CO4AANTCsGHDNHToUHXo0EEXXnihHnnkEUVHR2v79u1VfjYiIkKDBw/WiRMnLG0TwR0AYGtls+WtPvzhcrm0YsUKFRcXKy0trVqf6datmz7//HO/rlcRJtQBAFCBwsJCr9dOp1NOp9PnfXv37lVaWppKSkoUHR2tVatWqUuXLtW6xty5czVjxgz95je/Ua9evdSkSROv87GxsTVuN8EdQFgbdf4nFZ77y+ed67AlCBQzAOvcy8bck5OTvcpnzZql2bNn+7y/Y8eO2rNnjwoKCrRy5UqNHz9emzZtqlaAHzp0qCTpuuuu83oinWmaMgzDry1fCe4AAFsL5ENs8vLyvDLn8rJ2SYqMjNQFF1wgSerVq5d27typp556Ss8++2yV19qwYYMFLfZGcAcAoAJly9tqyu12q7S0tFrvveKKK2pcf1WYUAcAsDWXJJcMi4/qmzlzpjZv3qwvvvhCe/fu1cyZM7Vx40aNHTu22nX885//1K233qq+ffvq66+/liT9+c9/1nvvvVezm/FfBHcAAGrh2LFjGjdunDp27Kirr75aO3fu1Lp163TNNddU6/Ovvfaa0tPT1ahRI+3evduT8RcUFOjRRx/1q010ywMAbK2mD52pbp3VtWTJklpda+7cuVq8eLHGjRunFStWeMr79eunuXPn+lUnmTsAAEF04MABDRjguytiXFyc30+uI3MHEPJu/HxXpedXnt/br3orWyaH2ispPK15dXAdu2/5mpiYqEOHDqldu3Ze5e+9957OP/98v+okcwcAIIhuu+023XXXXXr//fdlGIYOHz6sl156STNmzNDtt9/uV51k7gAAW3OZhlymtZm21fVV5r777pPb7dbVV1+t06dPa8CAAXI6nZoxY4buuOMOv+okuAMAbM3u3fKGYeiBBx7QPffco0OHDqmoqEhdunRRdHS033XSLQ8AQBBNmjRJp06dUmRkpLp06aJLL71U0dHRKi4u1qRJk/yqk+AOALC1YO/nXlvPP/+8vvvuO5/y7777Ti+88IJfddItDwBAEBQWFso0TZmmqVOnTikqKspzzuVy6e2331arVq38qpvgDsD2Klsq5+8yOdiHWw65Le6Itrq+8jRt2lSGYcgwDF144YU+5w3D0Jw5c/yqm+AOAEAQbNiwQaZpauDAgXrttdcUHx/vORcZGam2bdsqKSnJr7oJ7gAAWzNNQ26Ll66ZdbAUrmw3uNzcXKWkpHjt5V5bTKgDACCIPvnkE23ZssXzOjs7Wz179tQtt9yiEydO+FUnwR0AYGvWb/d67qgr99xzjwoLCyVJe/fuVWZmpoYOHarc3FxlZmb6VSfd8gAAWzNNw/Ju9Lroli+Tm5urLl26SDq3/euwYcP06KOPavfu3Ro6dKhfdZK5AwAQRJGRkTp9+rQk6R//+IcGDx4sSYqPj/dk9DVF5g4AsDW7P362f//+yszMVL9+/bRjxw698sorkqRPP/1Ubdq08atOgjuAsFbVdrEInKJTpXWy5avdPfPMM/rlL3+plStXatGiRTrvvPMkSWvWrNFPf/pTv+okuAMAbM3uu8KlpKRo9erVPuXz58/3u06COwAAQfTll19Wej4lJaXGdRLcAQC2Zvcx93bt2lX6ABuXy1XjOgnuAAAE0QcffOD1+uzZs/rggw/05JNP6pFHHvGrToI7AMDW7L7OvUePHj5lvXv3VlJSkh577DGNGDGixnXWaJ17VlaWLrnkEsXExKhVq1YaPny4Dhw44PWekpISZWRkqHnz5oqOjtbIkSN19OjRGjcMAIDqKOuWt/oIto4dO2rnzp1+fbZGmfumTZuUkZGhSy65RN9//73uv/9+DR48WB9//LGaNGkiSZo+fbreeustvfrqq4qLi9PUqVM1YsQIr+fmhqqPxg2o8FzXFzYH7sIPX1XxuV9vCNx1gZqq6vexst/lKlT2b6yyf5uA3f34QTWmaerIkSOaPXu2OnTo4FedNQrua9eu9Xq9bNkytWrVSjk5ORowYIAKCgq0ZMkSLV++XAMHDpQkLV26VJ07d9b27dt12WWX+dVIAAAq4g7ArnBW11eZsn3df8g0TSUnJ2vFihV+1VmrMfeCggJJ8uxBm5OTo7Nnz2rQoEGe93Tq1EkpKSnatm0bwR0AgB/ZsMG7R8zhcKhly5a64IIL1KCBf2Ha7+Dudrs1bdo09evXT926dZMk5efnKzIyUk2bNvV6b0JCgvLz88utp7S0VKWlpZ7X/j5HFwBQP7kD8BCbuszcy/Z1t5LfwT0jI0P79u3Te++9V6sGZGVlac6cObWqAwAAO/nrX/9a7fded911Na7fr+A+depUrV69Wps3b/Z6qH1iYqLOnDmjkydPemXvR48eVWJiYrl1zZw502u/2sLCQiUnJ/vTLABAPWRKMi2e3W5aWpuv4cOHV+t9hmH49RCbGi2FM01TU6dO1apVq/Tuu+8qNTXV63yvXr3UsGFDrV+/3lN24MABffnll0pLSyu3TqfTqdjYWK8DAIBw5na7q3X4E9ilGmbuGRkZWr58ud58803FxMR4xtHj4uLUqFEjxcXFafLkycrMzFR8fLxiY2N1xx13KC0tjcl0AICAsPts+UCoUXBftGiRJOnKK6/0Kl+6dKkmTJgg6dwuNg6HQyNHjlRpaanS09O1cOFCSxoLoH6q6jkTrIOv31ymIYcNd4V79913NXXqVG3fvt2n17qgoEB9+/bVokWLNGBAzX+/axTcTbPqUYioqChlZ2crOzu7xo0BAKC+WLBggW677bZyh6Pj4uL0f//3f5o/f75fwb1GY+4AAIQatxmYI9A+/PBD/fSnP63w/ODBg5WTk+NX3QR3AACC4OjRo2rYsGGF5xs0aKDjx4/7VTfBHQBga2W7wll9BNp5552nffv2VXj+X//6l1q3bu1X3QR3AACCYOjQoXrooYdUUlLic+67777TrFmz9LOf/cyvutnPHQBga3ZdCvfggw/q9ddf14UXXqipU6eqY8eOkqT9+/crOztbLpdLDzzwgF91E9xDXVVbaLIlLOpSLbZ0DaSAbskMvxWWfh/sJoS0hIQEbd26VbfffrtmzpzpWZFmGIbS09OVnZ2thIQEv+omuAMAbM0tQ26LHz9rdX0Vadu2rd5++22dOHFChw4dkmma6tChg5o1a1aregnuAABbs+tDbH6oWbNmuuSSSyyrjwl1AACEGTJ3AICtBWLpWl0shQskMncAAMIMmTsAwNZMtyG32+LM3eL66hqZOwAAYYbMvZqq2lIyaOtsK1t3zBp4APWAyzRk2Hy2vNXI3AEACDNk7gAAW7Pr42cDieAOALA1UwFYCldHT6gLFLrlAQAIM2TuAABbo1veF5k7AABhhszdIpUtlQvJZXISS+VQvhDd1hWoiNs8d1hdp52RuQMAEGbI3AEAtuZyGzIsflysi8fPAgCAUELmDgCwNbZ89UVwBwDYGkvhfNEtDwBAmCFzBwDYmtttWD4Bzur94esawb0+Y7tY+2ItOoBKENwBALbmDsB+7oy5AwCAkELmDgCwNdN97rC6TjsjcwcAIMwQ3AEAtnZu4xjD4qP618/KytIll1yimJgYtWrVSsOHD9eBAwcC94WrgeAOALA1t9sIyFFdmzZtUkZGhrZv36533nlHZ8+e1eDBg1VcXBzAb105xtzrQGXbwUpB3BK2MrVZasUyuv9hyRoQ9tauXev1etmyZWrVqpVycnI0YEDl//8PFII7AMDWXKYhWbx0zVWL+goKCiRJ8fHxVjWnxgjuAABUoLCw0Ou10+mU0+ms8P1ut1vTpk1Tv3791K1bt0A3r0KMuQMAbM10GwE5JCk5OVlxcXGeIysrq9K2ZGRkaN++fVqxYkVdfPUKkbkDAFCBvLw8xcbGel5XlrVPnTpVq1ev1ubNm9WmTZu6aF6FCO4AAFtzSzJqsHStunVKUmxsrFdwL49pmrrjjju0atUqbdy4UampqdY2xg8EdwAAaiEjI0PLly/Xm2++qZiYGOXn50uS4uLi1KhRo6C0ieAOALA1t9uQgrjl66JFiyRJV155pVf50qVLNWHCBAtbVX0E9xBQ1Tr4yrBG3iKsRwfgJ9O0eEzAAgR3AICtBTtzD0UEdwCArZmmIdPih9hYXV9dY507AABhhswdAGBrbrf+t3bNyjptjMwdAIAwQ+YOALA1JtT5IrjbXGXL6EJymVxVWJJmibBbXgmgRgjuAABbc/1goxer2D1zZ8wdAIAwQ+YOALA1xtx9EdwBALZmus8dVtdpZ3TLAwAQZsjcAQC25grA42fdNn/8LME9jFW1HIolT4FXmyVpwRJ2yyuBeojgDgCwNdM0LJ8Ax8YxAAAgpJC5AwBsze2WDGbLeyFzBwAgzJC5AwBszQzAQ2ysfpxtXSO4AwBsze02ZBDcvdS4W37z5s0aNmyYkpKSZBiG3njjDa/zpmnq4YcfVuvWrdWoUSMNGjRIBw8etKq9AACgCjXO3IuLi9WjRw9NmjRJI0aM8Dn/u9/9Tk8//bSef/55paam6qGHHlJ6ero+/vhjRUVFWdJoWMPfNdj1ba2zHdeqBwrPTkAocjGhzkeNg/uQIUM0ZMiQcs+ZpqkFCxbowQcf1PXXXy9JeuGFF5SQkKA33nhDo0ePrl1rAQBAlSydLZ+bm6v8/HwNGjTIUxYXF6c+ffpo27Zt5X6mtLRUhYWFXgcAANXldhsBOezM0uCen58vSUpISPAqT0hI8Jz7saysLMXFxXmO5ORkK5sEAEC9E/R17jNnzlRBQYHnyMvLC3aTAAA2YrqMgBx2ZmlwT0xMlCQdPXrUq/zo0aOecz/mdDoVGxvrdQAAAP9ZGtxTU1OVmJio9evXe8oKCwv1/vvvKy0tzcpLAQAg6dxs+UAcdlbj2fJFRUU6dOiQ53Vubq727Nmj+Ph4paSkaNq0aZo7d646dOjgWQqXlJSk4cOHW9luBBFLw+rGyvN7+/3ZGz/fZWFLgNDGQ2x81Ti479q1S1dddZXndWZmpiRp/PjxWrZsmX71q1+puLhYP//5z3Xy5En1799fa9euZY07AAB1pMbB/corr5RpmhWeNwxDv/71r/XrX/+6Vg0DAKA6TDMAD52pOMzZQtBnywMAAGuxcQwAwN4Yc/dB5g4AQJghcwcA2FqESzIsfuiM6ZJcltZYt8jcAQAIM2TuQADVZq16oK4byDXwlT0Dge1gESiOAG35aufMneAOALA1BxPqfNAtDwBAmCFzBwDYmuE6d1jKzn3yInMHACDskLkDAGwtgjF3H2TuAACEGTJ3oArBWs4WKFV9H7aLhd0EaimcnZG5AwAQZsjcAQC25nAb1j9+1uZj7gR3AICtGQGYUCebB3e65QEACDNk7gAAW3O4zh1WcvMQGwAAEErI3AEAtuZwG3Iw5u6FzB0AgDBD5g4AsLVAjLmzcQwAAAgpZO4AAFsLxDp3y9fN1zGCOwDA1iIC0C1v+f7wdYxueQAAwgyZOwDA1hzmuZ3hLGVaXF8dI7gDCr9tXQHUbwR3AICtOVyGHBbvCier66tjjLkDABBmyNwBALZmuM8dVtdpZ2TuAACEGTJ3AICtRQRgzN2w+Zg7wR0AYGtGAB5iY/IQGwAAEErI3FEvsI4dCF+B2M/drGF9mzdv1mOPPaacnBwdOXJEq1at0vDhwy1tU02QuQMAUEvFxcXq0aOHsrOzg90USWTuAACbM1zWb/RS0/qGDBmiIUOGWNuIWiBzBwAgzJC5AwBsLcJtKMLqpWv/HXMvLCz0KnY6nXI6ndZeKwDI3AEAqEBycrLi4uI8R1ZWVrCbVC1k7gAAW3MEcJ17Xl6eYmNjPeV2yNolgjsAABWKjY31Cu52QXAHANiaw33usJJZw/qKiop06NAhz+vc3Fzt2bNH8fHxSklJsbZx1UBwBwDYmuEyLH8WfE3r27Vrl6666irP68zMTEnS+PHjtWzZMiubVi0EdwAAaunKK6+UaZrBboYHwR0AYGsRrnOHpdg4BgAAhBIydwCArQVyKZxdkbkDABBmyNwRNtjW1RqV3ccbP99Vhy0BqsdwG3JYPFvebfEWsnWNzB0AgDBD5g4AsDXDfe6wuk47I7gDAGwtEEvhmFAHAABCCpk7AMDWHC7rJ9RZXV9dI3MHACDMkLkDIeovn3eu8Nyo8z+pw5YAoS0QD7Gxur66RuYOAECYIXMHANgambsvMncAAMIMmTsAwNaYLe+L4A4AsDWHOwDd8jZ/Ql3AuuWzs7PVrl07RUVFqU+fPtqxY0egLgUAAH4gIMH9lVdeUWZmpmbNmqXdu3erR48eSk9P17FjxwJxOQBAPVY2oc7qw84C0i3/5JNP6rbbbtPEiRMlSYsXL9Zbb72lP/3pT7rvvvsCcUnAdipbx17bz4biOviPxg2o9HzXFzbXUUuA8Gd55n7mzBnl5ORo0KBB/7uIw6FBgwZp27ZtVl8OAFDPGQHI2g0yd2/ffPONXC6XEhISvMoTEhK0f/9+n/eXlpaqtLTU87qwsNDqJgEAUK8EfZ17VlaW4uLiPEdycnKwmwQAsJGypXBWH3ZmeXBv0aKFIiIidPToUa/yo0ePKjEx0ef9M2fOVEFBgefIy8uzukkAANQrlgf3yMhI9erVS+vXr/eUud1urV+/XmlpaT7vdzqdio2N9ToAAKguZsv7Cshs+czMTI0fP169e/fWpZdeqgULFqi4uNgze74ypmlKkoqLSqt4J+CtpPB0sJtQI65TpwJWd6DuRdGpwP27LCz9PmB1IzjKfqZl/18PFIdLclicqhLcy3HzzTfr+PHjevjhh5Wfn6+ePXtq7dq1PpPsynPqv//Du/ry+YFoGlAvzLNZvQhvp06dUlxcXLCbUa8YZqD/pKoht9utw4cPKyYmRoZhqLCwUMnJycrLy6PLvhLcp+rjXlUP96n6uFflM01Tp06dUlJSkhxWp9Y6d9/j4uI07Or/qGEDa+/72e8L9bf18SooKLDlzzTkni3vcDjUpk0bn3LG46uH+1R93Kvq4T5VH/fKFxl7cIRccAcAoCYcLkMOg13hfijo69wBAIC1Qj5zdzqdmjVrlpxOZ7CbEtK4T9XHvaoe7lP1ca+Cy+GSHBYn2nafLR9yE+oAAKiOsgl1N1x+IiAT6lb9sxkT6gAACAYyd18EdwCArRHcfTGhDgCAMBPywT07O1vt2rVTVFSU+vTpox07dgS7SUG1efNmDRs2TElJSTIMQ2+88YbXedM09fDDD6t169Zq1KiRBg0apIMHDwansUGUlZWlSy65RDExMWrVqpWGDx+uAwcOeL2npKREGRkZat68uaKjozVy5EifDY/qg0WLFql79+6eNdppaWlas2aN5zz3qXzz5s2TYRiaNm2ap4x7FRzs5+4rpIP7K6+8oszMTM2aNUu7d+9Wjx49lJ6ermPHjgW7aUFTXFysHj16KDs7u9zzv/vd7/T0009r8eLFev/999WkSROlp6erpKSkjlsaXJs2bVJGRoa2b9+ud955R2fPntXgwYNVXFzsec/06dP1t7/9Ta+++qo2bdqkw4cPa8SIEUFsdXC0adNG8+bNU05Ojnbt2qWBAwfq+uuv10cffSSJ+1SenTt36tlnn1X37t29yrlXCBUhPVu+T58+uuSSS/TMM89IOvdo2uTkZN1xxx267777gty64DMMQ6tWrdLw4cMlncvak5KSdPfdd2vGjBmSpIKCAiUkJGjZsmUaPXp0EFsbXMePH1erVq20adMmDRgwQAUFBWrZsqWWL1+uG2+8UZK0f/9+de7cWdu2bdNll10W5BYHV3x8vB577DHdeOON3KcfKSoq0sUXX6yFCxdq7ty56tmzpxYsWMDvVBCUzZYfffFJRUZYO6P9jKtQK3Y3te1s+ZDN3M+cOaOcnBwNGjTIU+ZwODRo0CBt27YtiC0LXbm5ucrPz/e6Z3FxcerTp0+9v2cFBQWSzgUtScrJydHZs2e97lWnTp2UkpJSr++Vy+XSihUrVFxcrLS0NO5TOTIyMnTttdd63ROJ3ymElpCdLf/NN9/I5XL57CSXkJCg/fv3B6lVoS0/P1+Syr1nZefqI7fbrWnTpqlfv37q1q2bpHP3KjIyUk2bNvV6b329V3v37lVaWppKSkoUHR2tVatWqUuXLtqzZw/36QdWrFih3bt3a+fOnT7n+J0KHofL+kzV7rPlQza4A1bJyMjQvn379N577wW7KSGrY8eO2rNnjwoKCrRy5UqNHz9emzZtCnazQkpeXp7uuusuvfPOO4qKigp2c4BKhWy3fIsWLRQREeEz0/To0aNKTEwMUqtCW9l94Z79z9SpU7V69Wpt2LDBa7fBxMREnTlzRidPnvR6f329V5GRkbrgggvUq1cvZWVlqUePHnrqqae4Tz+Qk5OjY8eO6eKLL1aDBg3UoEEDbdq0SU8//bQaNGighIQE7lWQWD1Tvuyws5AN7pGRkerVq5fWr1/vKXO73Vq/fr3S0tKC2LLQlZqaqsTERK97VlhYqPfff7/e3TPTNDV16lStWrVK7777rlJTU73O9+rVSw0bNvS6VwcOHNCXX35Z7+5Vedxut0pLS7lPP3D11Vdr79692rNnj+fo3bu3xo4d6/lv7lVwENx9hXS3fGZmpsaPH6/evXvr0ksv1YIFC1RcXKyJEycGu2lBU1RUpEOHDnle5+bmas+ePYqPj1dKSoqmTZumuXPnqkOHDkpNTdVDDz2kpKQkz4z6+iIjI0PLly/Xm2++qZiYGM+YZ1xcnBo1aqS4uDhNnjxZmZmZio+PV2xsrO644w6lpaXVu1nNM2fO1JAhQ5SSkqJTp05p+fLl2rhxo9atW8d9+oGYmBjPnI0yTZo0UfPmzT3l3CuEipAO7jfffLOOHz+uhx9+WPn5+erZs6fWrl3rM2GsPtm1a5euuuoqz+vMzExJ0vjx47Vs2TL96le/UnFxsX7+85/r5MmT6t+/v9auXVvvxggXLVokSbryyiu9ypcuXaoJEyZIkubPny+Hw6GRI0eqtLRU6enpWrhwYR23NPiOHTumcePG6ciRI4qLi1P37t21bt06XXPNNZK4TzXBvQoOJtT5Cul17gAAVKRsnfuECwOzzn3Zp/Zd5x7SmTsAAFUhc/cVshPqAACAf8jcAQC25nBJDosHmB1ua+ura2TuAACEGTJ3AICtOVyGHKZhbZ1ua+urawR3AICtGQHoljfolgcAAKGEzB0AYGtMqPNF5g4AQJghcwcA2BqZuy8ydwAAwgyZOwDA1sjcfZG5AwAQZsjcAQC25nAHIHO3+X6pBHcAgK05XJLD4gfK2T240y0PAECYIXMHANia43sy9x8jcwcAIMyQuQMAbI0xd19k7gAAWCA7O1vt2rVTVFSU+vTpox07dgStLQR3AICtOVyBOWrilVdeUWZmpmbNmqXdu3erR48eSk9P17FjxwLzpatAcAcAoJaefPJJ3XbbbZo4caK6dOmixYsXq3HjxvrTn/4UlPYQ3AEAtma4rc/ajRo8fvbMmTPKycnRoEGDPGUOh0ODBg3Stm3bAvCNq8aEOgCArZWqMGB1FhZ61+10OuV0Or3KvvnmG7lcLiUkJHiVJyQkaP/+/Za3rToI7gAAW4qMjFRiYqLm5ycHpP7o6GglJ3vXPWvWLM2ePTsg17MSwR0AYEtRUVHKzc3VmTNnAlK/aZoyDO81dj/O2iWpRYsWioiI0NGjR73Kjx49qsTExIC0rSoEdwCAbUVFRSkqKiqobYiMjFSvXr20fv16DR8+XJLkdru1fv16TZ06NShtIrgDAFBLmZmZGj9+vHr37q1LL71UCxYsUHFxsSZOnBiU9hDcAQCopZtvvlnHjx/Xww8/rPz8fPXs2VNr1671mWRXVwzTNG3+kD0AAPBDrHMHACDMENwBAAgzBHcAAMIMwR0AgDBDcAcAIMwQ3AEACDMEdwAAwgzBHQCAMENwBwAgzBDcAQAIMwR3AADCDMEdAIAw8/8BBmfiVEvRUTAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gene_data, spatial_locations, original_adata, TRUE_PRIOR_WEIGHTS = prepare_synthetic_data(num_clusters=num_clusters, data_dimension=data_dimension)\n",
    "prior_means = torch.zeros(num_clusters, gene_data.shape[1])\n",
    "prior_scales = torch.ones(num_clusters, gene_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(gene_data).float()\n",
    "num_obs, data_dim = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Given a graph-based flow prior and a GMM for the likelihood, how can we get a good posterior? \n",
    "\n",
    "In BayXenSmooth, we attempted to do this via an SVI framework where the posterior was approximated by another distribution with a desired paramteric form. This can be useful, but we want to model more complicated posteriors. This is where normalizing flows come in. By learning the posterior outcomes with complicated flows, we can plug in the flow as a variational distribution and train the variational inference procedure in a similar backprop way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior and Likelihood Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Params to Set\n",
    "neighborhood_size = 1\n",
    "neighborhood_agg = \"mean\"\n",
    "num_pcs = 3\n",
    "\n",
    "def custom_cluster_initialization(original_adata, method, K=17):\n",
    "\n",
    "    original_adata.generate_neighborhood_graph(original_adata.xenium_spot_data, plot_pcas=False)\n",
    "\n",
    "    # This function initializes clusters based on the specified method\n",
    "    if method == \"K-Means\":\n",
    "        initial_clusters = original_adata.KMeans(original_adata.xenium_spot_data, save_plot=False, K=K, include_spatial=False)\n",
    "    elif method == \"Hierarchical\":\n",
    "        initial_clusters = original_adata.Hierarchical(original_adata.xenium_spot_data, save_plot=True, num_clusters=K)\n",
    "    elif method == \"Leiden\":\n",
    "        initial_clusters = original_adata.Leiden(original_adata.xenium_spot_data, resolutions=[0.35], save_plot=False, K=K)[0.35]\n",
    "    elif method == \"Louvain\":\n",
    "        initial_clusters = original_adata.Louvain(original_adata.xenium_spot_data, resolutions=[0.35], save_plot=False, K=K)[0.35]\n",
    "    elif method == \"mclust\":\n",
    "        original_adata.pca(original_adata.xenium_spot_data, num_pcs)\n",
    "        initial_clusters = original_adata.mclust(original_adata.xenium_spot_data, G=K, model_name = \"EEE\")\n",
    "    elif method == \"random\":\n",
    "        initial_clusters = np.random.randint(0, K, size=original_adata.xenium_spot_data.X.shape[0])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    return initial_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# Clamping\n",
    "MIN_CONCENTRATION = 0.01\n",
    "\n",
    "num_posterior_samples = 10\n",
    "\n",
    "spatial_init_data = StandardScaler().fit_transform(gene_data)\n",
    "gene_data = StandardScaler().fit_transform(gene_data)\n",
    "empirical_prior_means = torch.zeros(num_clusters, spatial_init_data.shape[1])\n",
    "empirical_prior_scales = torch.ones(num_clusters, spatial_init_data.shape[1])\n",
    "\n",
    "rows = spatial_locations[\"row\"].astype(int)\n",
    "columns = spatial_locations[\"col\"].astype(int)\n",
    "\n",
    "num_rows = max(rows) + 1\n",
    "num_cols = max(columns) + 1\n",
    "\n",
    "initial_clusters = custom_cluster_initialization(original_adata, \"K-Means\", K=num_clusters)\n",
    "\n",
    "ari = ARI(initial_clusters, TRUE_PRIOR_WEIGHTS.argmax(axis=-1))\n",
    "nmi = NMI(initial_clusters, TRUE_PRIOR_WEIGHTS.argmax(axis=-1))\n",
    "cluster_metrics = {\n",
    "    \"ARI\": round(ari, 2),\n",
    "    \"NMI\": round(nmi, 2)\n",
    "}\n",
    "print(\"K-Means Metrics: \", cluster_metrics)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    cluster_data = gene_data[initial_clusters == i]\n",
    "    if cluster_data.size > 0:  # Check if there are any elements in the cluster_data\n",
    "        empirical_prior_means[i] = torch.tensor(cluster_data.mean(axis=0))\n",
    "        empirical_prior_scales[i] = torch.tensor(cluster_data.std(axis=0))\n",
    "cluster_probs_prior = torch.zeros((initial_clusters.shape[0], num_clusters))\n",
    "cluster_probs_prior[torch.arange(initial_clusters.shape[0]), initial_clusters - 1] = 1.\n",
    "\n",
    "locations_tensor = torch.tensor(spatial_locations.to_numpy())\n",
    "\n",
    "# Compute the number of elements in each dimension\n",
    "num_spots = cluster_probs_prior.shape[0]\n",
    "\n",
    "# Initialize an empty tensor for spatial concentration priors\n",
    "spatial_cluster_probs_prior = torch.zeros_like(cluster_probs_prior, dtype=torch.float64)\n",
    "\n",
    "spot_locations = KDTree(locations_tensor.cpu())  # Ensure this tensor is in host memory\n",
    "neighboring_spot_indexes = spot_locations.query_ball_point(locations_tensor.cpu(), r=neighborhood_size, p=1, workers=8)\n",
    "\n",
    "# Iterate over each spot\n",
    "for i in tqdm(range(num_spots)):\n",
    "\n",
    "    # Select priors in the neighborhood\n",
    "    priors_in_neighborhood = cluster_probs_prior[neighboring_spot_indexes[i]]\n",
    "\n",
    "    # Compute the sum or mean, or apply a custom weighting function\n",
    "    if neighborhood_agg == \"mean\":\n",
    "        neighborhood_priors = priors_in_neighborhood.mean(dim=0)\n",
    "    else:\n",
    "        locations = original_adata.xenium_spot_data.obs[[\"x_location\", \"y_location\", \"z_location\"]].values\n",
    "        neighboring_locations = locations[neighboring_spot_indexes[i]].astype(float)\n",
    "        distances = torch.tensor(np.linalg.norm(neighboring_locations - locations[i], axis=1))\n",
    "        def distance_weighting(x):\n",
    "            weight = 1/(1 + x/1)\n",
    "            # print(weight)\n",
    "            return weight / weight.sum()\n",
    "        neighborhood_priors = (priors_in_neighborhood * distance_weighting(distances).reshape(-1, 1)).sum(dim=0)\n",
    "    # Update the cluster probabilities\n",
    "    spatial_cluster_probs_prior[i] += neighborhood_priors\n",
    "\n",
    "spatial_cluster_probs_prior = spatial_cluster_probs_prior.clamp(MIN_CONCENTRATION)\n",
    "sample_for_assignment_options = [True, False]\n",
    "\n",
    "num_prior_samples = 10\n",
    "for sample_for_assignment in sample_for_assignment_options:\n",
    "\n",
    "    if sample_for_assignment:\n",
    "        cluster_assignments_prior_TRUE = pyro.sample(\"cluster_assignments\", dist.Categorical(spatial_cluster_probs_prior).expand_by([num_prior_samples])).detach().mode(dim=0).values\n",
    "        cluster_assignments_prior = cluster_assignments_prior_TRUE\n",
    "    else:\n",
    "        cluster_assignments_prior_FALSE = spatial_cluster_probs_prior.argmax(dim=1)\n",
    "        cluster_assignments_prior = cluster_assignments_prior_FALSE\n",
    "\n",
    "    # Load the data\n",
    "    data = torch.tensor(gene_data).float()\n",
    "\n",
    "    cluster_grid_PRIOR = torch.zeros((num_rows, num_cols), dtype=torch.long)\n",
    "\n",
    "    cluster_grid_PRIOR[rows, columns] = cluster_assignments_prior + 1\n",
    "\n",
    "    colors = plt.cm.get_cmap('viridis', num_clusters)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cluster_grid_PRIOR.cpu(), cmap=colors, interpolation='nearest', origin='lower')\n",
    "    plt.colorbar(ticks=range(1, num_clusters + 1), label='Cluster Values')\n",
    "    plt.title('Prior Cluster Assignment with BayXenSmooth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editing the Hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a graph of the spots.\n",
    "\n",
    "The idea is that the edges are connections between spots while the node attributes are gene expressions.\n",
    "\n",
    "We start by creating a regular normalizing flow and then updating the hypernetwork to be a GCN. Note that different flow types express their NNs as different attributes, so we need to have a helper function edit the hypernetwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric as pyg\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, SGConv, SAGEConv, CuGraphSAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric import EdgeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_flow_nn(flow, network):\n",
    "    match type(flow):\n",
    "        case zuko.flows.continuous.CNF:\n",
    "            flow.transform.ode = network\n",
    "        case zuko.flows.autoregressive.MAF:\n",
    "            flow.\n",
    "        case _:\n",
    "            # Handle default case\n",
    "            pass\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_probs_graph_flow_dist = setup_zuko_flow(\n",
    "    flow_type=\"CNF\",\n",
    "    flow_length=8,\n",
    "    num_clusters=num_clusters,\n",
    "    context_length=data_dim,\n",
    "    hidden_layers=(128, 128, 128)\n",
    ")\n",
    "\n",
    "class GCNFlowModel(nn.Module):\n",
    "    def __init__(self, original_graph, in_features, num_clusters, conv_type=\"GCN\"):\n",
    "        super().__init__()\n",
    "        self.x = original_graph.x\n",
    "        self.edge_index = original_graph.edge_index\n",
    "        self.set_layers(in_features, num_clusters, conv_type)\n",
    "\n",
    "    def set_layers(self, in_features, num_clusters, conv_type):\n",
    "        match conv_type:\n",
    "            case \"GCN\":\n",
    "                self.layers = nn.ModuleList([\n",
    "                    GCNModule(in_features, 64, conv_type),\n",
    "                    nn.ReLU(),\n",
    "                    GCNModule(64, 64, conv_type),\n",
    "                    nn.ReLU(),\n",
    "                    GCNModule(64, 64, conv_type),\n",
    "                    nn.ReLU(),\n",
    "                    GCNModule(64, num_clusters, conv_type)\n",
    "                ])\n",
    "            case \"SGCN\":\n",
    "                self.layers =  nn.ModuleList([\n",
    "                    GCNModule(in_features, num_clusters, conv_type),\n",
    "                ])\n",
    "            case \"SAGE\" | \"cuSAGE\":\n",
    "                self.layers = nn.ModuleList([\n",
    "                    GCNModule(in_features, 64, conv_type),\n",
    "                    nn.ReLU(),\n",
    "                    GCNModule(64, 64, conv_type),\n",
    "                    nn.ReLU(),\n",
    "                    GCNModule(64, 64, conv_type),\n",
    "                    nn.ReLU(),\n",
    "                    GCNModule(64, num_clusters, conv_type)\n",
    "                ])\n",
    "            case _:\n",
    "                raise NotImplementedError(f\"{conv_type} not supported yet.\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, GCNModule):\n",
    "                x = layer(x, self.edge_index)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GCNModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv=\"GCN\"):\n",
    "        super().__init__()\n",
    "        match conv:\n",
    "            case \"GCN\":\n",
    "                self.conv = GCNConv(in_channels, out_channels)\n",
    "            case \"SGCN\":\n",
    "                self.conv = SGConv(in_channels, out_channels, K=neighborhood_size)\n",
    "            case \"SAGE\":\n",
    "                self.conv = SAGEConv(in_channels, out_channels)\n",
    "            case \"cuSAGE\":\n",
    "                self.conv = CuGraphSAGEConv(in_channels, out_channels)\n",
    "            case _:\n",
    "                raise NotImplementedError(\"This convolutional layer does not have support.\")\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.conv(x, edge_index)\n",
    "\n",
    "positions = torch.tensor(spatial_locations.to_numpy()).float()\n",
    "edge_index = pyg.nn.knn_graph(positions, k=1+4*neighborhood_size, loop=True)\n",
    "GRAPH_CONV = \"SGCN\"\n",
    "\n",
    "input_x = torch.tensor(original_adata.xenium_spot_data.X, dtype=torch.float32)\n",
    "graph = Data(x=data, edge_index=edge_index)\n",
    "\n",
    "print(f\"graph.x shape: {graph.x.shape}, data_dim: {data_dim}\")\n",
    "print(f\"original_adata.xenium_spot_data.X shape: {original_adata.xenium_spot_data.X.shape}\")\n",
    "print(f\"Original MLP Dimensions: {cluster_probs_graph_flow_dist.transform.ode[0].weight.shape}\")\n",
    "\n",
    "cluster_probs_graph_flow_dist.transform.ode = GCNFlowModel(\n",
    "    original_graph=graph,\n",
    "    in_features=cluster_probs_graph_flow_dist.transform.ode[0].weight.shape[1],\n",
    "    num_clusters=num_clusters,\n",
    "    conv_type=GRAPH_CONV,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "NUM_PARTICLES = 5\n",
    "\n",
    "expected_total_param_dim = 2 # K x D\n",
    "cluster_states = cluster_grid_PRIOR.clone()\n",
    "\n",
    "def model(data):\n",
    "\n",
    "    pyro.module(\"prior_flow\", cluster_probs_graph_flow_dist)\n",
    "    \n",
    "    with pyro.plate(\"clusters\", num_clusters):\n",
    "\n",
    "        # Define the means and variances of the Gaussian components\n",
    "        cluster_means = pyro.sample(\"cluster_means\", dist.Normal(prior_means, 10.0).to_event(1))\n",
    "        cluster_scales = pyro.sample(\"cluster_scales\", dist.LogNormal(prior_scales, 10.0).to_event(1))\n",
    "\n",
    "    cluster_logits = pyro.sample(\"cluster_logits\", ZukoToPyro(cluster_probs_graph_flow_dist(data)).to_event(1))\n",
    "    # print(\"MODEL \", cluster_logits.shape, data.shape)\n",
    "\n",
    "    # Define priors for the cluster assignment probabilities and Gaussian parameters\n",
    "    with pyro.plate(\"data\", len(data), subsample_size=batch_size) as ind:\n",
    "        batch_data = data[ind]\n",
    "        batch_logits = cluster_logits[..., ind, :]\n",
    "        # print(\"BATCH DATA: \", batch_data.shape)\n",
    "        # print(\"BATCH LOGITS: \", batch_logits.shape)\n",
    "        # likelihood for batch\n",
    "        if cluster_means.dim() == expected_total_param_dim:\n",
    "            pyro.sample(f\"obs\", dist.MixtureOfDiagNormals(\n",
    "                    cluster_means.unsqueeze(0).expand(batch_size, -1, -1), \n",
    "                    cluster_scales.unsqueeze(0).expand(batch_size, -1, -1), \n",
    "                    batch_logits.squeeze(1)\n",
    "                ), \n",
    "                obs=batch_data\n",
    "            )\n",
    "        # likelihood for batch WITH vectorization of particles\n",
    "        else:\n",
    "            pyro.sample(f\"obs\", dist.MixtureOfDiagNormals(\n",
    "                    cluster_means.unsqueeze(1).expand(-1, batch_size, -1, -1), \n",
    "                    cluster_scales.unsqueeze(1).expand(-1, batch_size, -1, -1), \n",
    "                    batch_logits.squeeze(1)\n",
    "                ), \n",
    "                obs=batch_data\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_probs_flow_dist = setup_zuko_flow(\n",
    "    flow_type=\"CNF\",\n",
    "    flow_length=32,\n",
    "    num_clusters=num_clusters,\n",
    "    context_length=data_dim,\n",
    "    hidden_layers=(128, 128, 128)\n",
    ")\n",
    "\n",
    "def guide(data):\n",
    "    \n",
    "    pyro.module(\"posterior_flow\", cluster_probs_flow_dist)\n",
    "\n",
    "    with pyro.plate(\"clusters\", num_clusters):\n",
    "        # Global variational parameters for cluster means and scales\n",
    "        cluster_means_q_mean = pyro.param(\"cluster_means_q_mean\", prior_means + torch.randn_like(prior_means) * 0.05)\n",
    "        cluster_scales_q_mean = pyro.param(\"cluster_scales_q_mean\", prior_scales + torch.randn_like(prior_scales) * 0.01, constraint=dist.constraints.positive)\n",
    "        if learn_global_variances:\n",
    "            cluster_means_q_scale = pyro.param(\"cluster_means_q_scale\", torch.ones_like(prior_means) * 1.0, constraint=dist.constraints.positive)\n",
    "            cluster_scales_q_scale = pyro.param(\"cluster_scales_q_scale\", torch.ones_like(prior_scales) * 0.25, constraint=dist.constraints.positive)\n",
    "            cluster_means = pyro.sample(\"cluster_means\", dist.Normal(cluster_means_q_mean, cluster_means_q_scale).to_event(1))\n",
    "            cluster_scales = pyro.sample(\"cluster_scales\", dist.LogNormal(cluster_scales_q_mean, cluster_scales_q_scale).to_event(1))\n",
    "        else:\n",
    "            cluster_means = pyro.sample(\"cluster_means\", dist.Delta(cluster_means_q_mean).to_event(1))\n",
    "            cluster_scales = pyro.sample(\"cluster_scales\", dist.Delta(cluster_scales_q_mean).to_event(1))\n",
    "\n",
    "    cluster_logits = pyro.sample(\"cluster_logits\", ZukoToPyro(cluster_probs_flow_dist(data)).to_event(1))\n",
    "    # print(\"GUIDE \", cluster_logits.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "NUM_EPOCHS = 1000\n",
    "NUM_BATCHES = int(math.ceil(data.shape[0] / batch_size))\n",
    "\n",
    "def per_param_callable(param_name):\n",
    "    if param_name == 'cluster_means_q_mean':\n",
    "        return {\"lr\": 0.001, \"betas\": (0.9, 0.999), \"clip_norm\": 5.0}\n",
    "    elif param_name == 'cluster_scales_q_mean':\n",
    "        return {\"lr\": 0.001, \"betas\": (0.9, 0.999), \"clip_norm\": 5.0}\n",
    "    elif \"logit\" in param_name:\n",
    "        return {\"lr\": 0.001, \"betas\": (0.9, 0.999), \"clip_norm\": 5.0}\n",
    "    else:\n",
    "        return {\"lr\": 0.001, \"betas\": (0.9, 0.999), \"clip_norm\": 5.0}\n",
    "\n",
    "# scheduler = Adam(per_param_callable)\n",
    "scheduler = ClippedAdam(per_param_callable)\n",
    "\n",
    "# Setup the inference algorithm\n",
    "svi = SVI(model, guide, scheduler, loss=TraceMeanField_ELBO(num_particles=NUM_PARTICLES, vectorize_particles=True))\n",
    "\n",
    "epoch_pbar = tqdm(range(NUM_EPOCHS))\n",
    "PATIENCE = 25\n",
    "current_min_loss = float('inf')\n",
    "patience_counter = 0\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    running_loss = 0.0\n",
    "    for step in range(NUM_BATCHES):\n",
    "        # with torch.amp.autocast(): THE OVERHEAD WASNT WORTH IT\n",
    "        loss = svi.step(data)\n",
    "        running_loss += loss / batch_size\n",
    "    epoch_pbar.set_description(f\"Epoch {epoch} : loss = {round(running_loss, 4)}\")\n",
    "    # print(f\"Epoch {epoch} : loss = {round(running_loss, 4)}\")\n",
    "    if running_loss > current_min_loss:\n",
    "        patience_counter += 1\n",
    "    else:\n",
    "        current_min_loss = running_loss\n",
    "        patience_counter = 0\n",
    "    if patience_counter >= PATIENCE:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model Results to Infinite Memory Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# save_path = os.path.join(\"/nfs/turbo/lsa-regier/scratch\", \"roko/nf_results\", \"test_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.get_param_store().save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.get_param_store().load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.get_param_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that should you decide to load a model, you will need to recreate the module with updated parameters as show in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_posterior_samples = 100\n",
    "cluster_probs_samples = []\n",
    "\n",
    "pyro.module(\"posterior_flow\", cluster_probs_flow_dist, update_module_params=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_posterior_samples):\n",
    "        with pyro.plate(\"data\", len(data)):\n",
    "            cluster_logits = pyro.sample(\"cluster_logits\", ZukoToPyro(cluster_probs_flow_dist(data).to_event(1)))\n",
    "\n",
    "            # Make the logits numerically stable\n",
    "            max_logit = torch.max(cluster_logits, dim=-1, keepdim=True).values\n",
    "            stable_logits = cluster_logits - max_logit\n",
    "            cluster_probs_sample = pyro.sample(\n",
    "                \"cluster_probs\",\n",
    "                dist.Delta(torch.nn.functional.softmax(stable_logits, dim=-1)).to_event(1)\n",
    "            )\n",
    "        torch.cuda.empty_cache()\n",
    "        cluster_probs_samples.append(cluster_probs_sample)\n",
    "        del cluster_probs_sample  # Explicitly delete\n",
    "cluster_probs_avg = torch.stack(cluster_probs_samples).mean(dim=0)\n",
    "cluster_assignments_posterior = cluster_probs_avg.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# get the true and prior weights\n",
    "CLAMP = 0.000001\n",
    "spatial_cluster_probs_prior = spatial_cluster_probs_prior.clamp(CLAMP)\n",
    "TRUE_WEIGHTS = torch.tensor(TRUE_PRIOR_WEIGHTS).clamp(CLAMP)\n",
    "\n",
    "prior_cm = confusion_matrix(TRUE_WEIGHTS.argmax(dim=-1).cpu().numpy(), cluster_assignments_prior.cpu().numpy())\n",
    "posterior_cm = confusion_matrix(TRUE_WEIGHTS.argmax(dim=-1).cpu().numpy(), cluster_assignments_posterior.cpu().numpy())\n",
    "\n",
    "_, prior_permutation = linear_sum_assignment(cost_matrix = prior_cm, maximize=True)\n",
    "_, posterior_permutation = linear_sum_assignment(cost_matrix = posterior_cm, maximize=True)\n",
    "\n",
    "print(prior_permutation, posterior_permutation)\n",
    "# verify that the labelling doesn't magically switch during the learning process\n",
    "if not np.all(prior_permutation == posterior_permutation):\n",
    "    print(\"WARNING: Labels changed from prior to posterior.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate KL on the permuted inferred values.\n",
    "kl_prior_divergence = torch.sum(TRUE_WEIGHTS * torch.log(TRUE_WEIGHTS / spatial_cluster_probs_prior[:, prior_permutation]), dim=1)\n",
    "kl_post_divergence = torch.sum(TRUE_WEIGHTS * torch.log(TRUE_WEIGHTS / cluster_probs_avg[:, posterior_permutation]), dim=1)\n",
    "print(kl_prior_divergence.mean(), kl_post_divergence.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 25\n",
    "TRUE_WEIGHTS[index], spatial_cluster_probs_prior[index], spatial_cluster_probs_prior[:, prior_permutation][index], cluster_probs_avg[index], cluster_probs_avg[:, posterior_permutation][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_KL_grid = torch.zeros(num_rows, num_cols, dtype=float)\n",
    "prior_KL_grid[rows, columns] = kl_prior_divergence\n",
    "cmap = plt.cm.get_cmap('coolwarm')\n",
    "plt.imshow(prior_KL_grid.cpu().numpy(), origin='lower', cmap=cmap)\n",
    "plt.colorbar(label='KL Divergence')\n",
    "plt.title(\"KL on Prior Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_KL_grid = torch.zeros(num_rows, num_cols, dtype=float)\n",
    "posterior_KL_grid[rows, columns] = kl_post_divergence\n",
    "cmap = plt.cm.get_cmap('coolwarm')\n",
    "plt.imshow(posterior_KL_grid.cpu().detach().numpy(), origin='lower', cmap=cmap)\n",
    "plt.colorbar(label='KL Divergence')\n",
    "plt.title(\"KL on Posterior Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = spatial_locations[\"row\"].astype(int)\n",
    "columns = spatial_locations[\"col\"].astype(int)\n",
    "\n",
    "num_rows = max(rows) + 1\n",
    "num_cols = max(columns) + 1\n",
    "\n",
    "cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.long)\n",
    "\n",
    "cluster_grid[rows, columns] = cluster_assignments_posterior + 1\n",
    "\n",
    "colors = plt.cm.get_cmap('viridis', num_clusters + 1)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cluster_grid.cpu(), cmap=colors, interpolation='nearest', origin='lower')\n",
    "plt.colorbar(ticks=range(1, num_clusters + 1), label='Cluster Values')\n",
    "plt.title('Posterior Cluster Assignment with XenNF')\n",
    "\n",
    "ari = ARI(cluster_assignments_posterior.cpu().numpy(), TRUE_PRIOR_WEIGHTS.argmax(axis=-1))\n",
    "nmi = NMI(cluster_assignments_posterior.cpu().numpy(), TRUE_PRIOR_WEIGHTS.argmax(axis=-1))\n",
    "cluster_metrics = {\n",
    "    \"ARI\": round(ari, 2),\n",
    "    \"NMI\": round(nmi, 2)\n",
    "}\n",
    "print(cluster_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
